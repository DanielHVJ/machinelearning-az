{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KdUFcDsdzRyw"
   },
   "source": [
    "# Clonamos el repositorio para obtener los dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mHReFf3_y9ms",
    "outputId": "c17545fd-c7dd-42c2-e3ad-4f55db21611f"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/joanby/machinelearning-az.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNKZXgtKzU2x"
   },
   "source": [
    "# Damos acceso a nuestro Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "5gu7KWnzzUQ0",
    "outputId": "abe602b4-3a59-470e-d508-037c6966002b"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1gUxIkHWzfHV"
   },
   "source": [
    "# Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mIQt3jBMzYRE"
   },
   "outputs": [],
   "source": [
    "!ls '/content/drive/My Drive' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mHsK36uN0XB-"
   },
   "source": [
    "# Google colab tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kTzwfUPWzrm4"
   },
   "outputs": [],
   "source": [
    "from google.colab import files # Para manejar los archivos y, por ejemplo, exportar a su navegador\n",
    "import glob # Para manejar los archivos y, por ejemplo, exportar a su navegador\n",
    "from google.colab import drive # Montar tu Google drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uab9OAbV8hYN"
   },
   "source": [
    "# Instalar dependendias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "qukjDgj98kE4",
    "outputId": "95b5f2b5-7149-436a-b1fb-ad567cc783bd"
   },
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3yFpBwmNz70v"
   },
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v8OxSXXSz-OP"
   },
   "source": [
    "# Cómo importar las librerías\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "edZX51YLzs59"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 9)\n",
    "plt.style.use('ggplot')\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from IPython.display import Image as PImage\n",
    "from subprocess import check_call\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8XfXlqtF0B58"
   },
   "source": [
    "# Importar el data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-nnozsHsz_-N"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Restaurant_Reviews.tsv\", delimiter = \"\\t\", quoting = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SsVEdPzf4XmV"
   },
   "source": [
    "# Limpieza de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v9CtwK834bjy"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "corpus = []\n",
    "for i in range(0, 1000):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5AH_uCEz68rb"
   },
   "source": [
    "# Crear el Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "oeuAy8LI69vi",
    "outputId": "10346439-d6ac-4abd-b5bb-033e9a284716"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cgweTaJ67BOB"
   },
   "source": [
    "# Dividir el data set en conjunto de entrenamiento y conjunto de testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2AwTWELX7DZQ"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajustar el clasificador en el Conjunto de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred  = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JnMLSqzW8NH7"
   },
   "source": [
    "# Elaborar una matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1qZ3wRR08Oar"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 83  60]\n [ 26 131]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "tp = cm[0,[0]]\n",
    "tn = cm[1,[1]]\n",
    "fn = cm[1,[0]]\n",
    "fp = cm[0,[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Naive Bayes: Accuracy: [0.71333333] Precision: [0.58041958] Recall: [0.76146789] F1: [0.65873016]\n"
     ]
    }
   ],
   "source": [
    "accu = (tp+tn)/(tp+tn+fn+fp)\n",
    "pre = tp/(tp+fp)\n",
    "rec = tp/(tp+fn)\n",
    "F1 = 2*pre*rec/(pre+rec)\n",
    "\n",
    "print('Naive Bayes:', 'Accuracy:',accu, 'Precision:',pre, 'Recall:',rec, 'F1:',F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([26])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": []
  },
  {
   "source": [
    "### Logistic regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred  = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[117  26]\n [ 60  97]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "tp = cm[0,[0]]\n",
    "tn = cm[1,[1]]\n",
    "fn = cm[1,[0]]\n",
    "fp = cm[0,[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Logistic: Accuracy: [0.71333333] Precision: [0.81818182] Recall: [0.66101695] F1: [0.73125]\n"
     ]
    }
   ],
   "source": [
    "accu = (tp+tn)/(tp+tn+fn+fp)\n",
    "pre = tp/(tp+fp)\n",
    "rec = tp/(tp+fn)\n",
    "F1 = 2*pre*rec/(pre+rec)\n",
    "\n",
    "print('Logistic:', 'Accuracy:',accu, 'Precision:',pre, 'Recall:',rec, 'F1:',F1)"
   ]
  },
  {
   "source": [
    "### KNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = \"minkowski\", p = 2)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred  = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[107  36]\n [ 67  90]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "tp = cm[0,[0]]\n",
    "tn = cm[1,[1]]\n",
    "fn = cm[1,[0]]\n",
    "fp = cm[0,[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNN: Accuracy: [0.65666667] Precision: [0.74825175] Recall: [0.61494253] F1: [0.67507886]\n"
     ]
    }
   ],
   "source": [
    "accu = (tp+tn)/(tp+tn+fn+fp)\n",
    "pre = tp/(tp+fp)\n",
    "rec = tp/(tp+fn)\n",
    "F1 = 2*pre*rec/(pre+rec)\n",
    "\n",
    "print('KNN:', 'Accuracy:',accu, 'Precision:',pre, 'Recall:',rec, 'F1:',F1)"
   ]
  },
  {
   "source": [
    "### SVM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = \"linear\", random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred  = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[111  32]\n [ 52 105]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "tp = cm[0,[0]]\n",
    "tn = cm[1,[1]]\n",
    "fn = cm[1,[0]]\n",
    "fp = cm[0,[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVC Linear: Accuracy: [0.72] Precision: [0.77622378] Recall: [0.6809816] F1: [0.7254902]\n"
     ]
    }
   ],
   "source": [
    "accu = (tp+tn)/(tp+tn+fn+fp)\n",
    "pre = tp/(tp+fp)\n",
    "rec = tp/(tp+fn)\n",
    "F1 = 2*pre*rec/(pre+rec)\n",
    "\n",
    "print('SVC Linear:', 'Accuracy:',accu, 'Precision:',pre, 'Recall:',rec, 'F1:',F1)"
   ]
  },
  {
   "source": [
    "### SVM RADIAL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(kernel = \"rbf\", random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred  = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[132  11]\n [ 73  84]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "tp = cm[0,[0]]\n",
    "tn = cm[1,[1]]\n",
    "fn = cm[1,[0]]\n",
    "fp = cm[0,[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVC Radial: Accuracy: [0.72] Precision: [0.92307692] Recall: [0.64390244] F1: [0.75862069]\n"
     ]
    }
   ],
   "source": [
    "accu = (tp+tn)/(tp+tn+fn+fp)\n",
    "pre = tp/(tp+fp)\n",
    "rec = tp/(tp+fn)\n",
    "F1 = 2*pre*rec/(pre+rec)\n",
    "\n",
    "print('SVC Radial:', 'Accuracy:',accu, 'Precision:',pre, 'Recall:',rec, 'F1:',F1)"
   ]
  },
  {
   "source": [
    "### Decision Tree"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = \"entropy\")\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred  = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[116  27]\n [ 62  95]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "tp = cm[0,[0]]\n",
    "tn = cm[1,[1]]\n",
    "fn = cm[1,[0]]\n",
    "fp = cm[0,[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Decision Tree: Accuracy: [0.70333333] Precision: [0.81118881] Recall: [0.65168539] F1: [0.72274143]\n"
     ]
    }
   ],
   "source": [
    "accu = (tp+tn)/(tp+tn+fn+fp)\n",
    "pre = tp/(tp+fp)\n",
    "rec = tp/(tp+fn)\n",
    "F1 = 2*pre*rec/(pre+rec)\n",
    "\n",
    "print('Decision Tree:', 'Accuracy:',accu, 'Precision:',pre, 'Recall:',rec, 'F1:',F1)"
   ]
  },
  {
   "source": [
    "### Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 5, criterion = \"entropy\")\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred  = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[103  40]\n [ 43 114]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "tp = cm[0,[0]]\n",
    "tn = cm[1,[1]]\n",
    "fn = cm[1,[0]]\n",
    "fp = cm[0,[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random Forest: Accuracy: [0.72333333] Precision: [0.72027972] Recall: [0.70547945] F1: [0.71280277]\n"
     ]
    }
   ],
   "source": [
    "accu = (tp+tn)/(tp+tn+fn+fp)\n",
    "pre = tp/(tp+fp)\n",
    "rec = tp/(tp+fn)\n",
    "F1 = 2*pre*rec/(pre+rec)\n",
    "\n",
    "print('Random Forest:', 'Accuracy:',accu, 'Precision:',pre, 'Recall:',rec, 'F1:',F1)"
   ]
  },
  {
   "source": [
    "### CART"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  1491  1492  1493  1494  1495  1496  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "4  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "\n",
       "   1497  1498  1499  y  \n",
       "0     0     0     0  1  \n",
       "1     0     0     0  0  \n",
       "2     0     0     0  0  \n",
       "3     0     0     0  1  \n",
       "4     0     0     0  1  \n",
       "\n",
       "[5 rows x 1501 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>1491</th>\n      <th>1492</th>\n      <th>1493</th>\n      <th>1494</th>\n      <th>1495</th>\n      <th>1496</th>\n      <th>1497</th>\n      <th>1498</th>\n      <th>1499</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1501 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "XT = pd.DataFrame(X)\n",
    "XT['y'] = pd.DataFrame(y)\n",
    "XT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Max Depth  Average Accuracy\n         1           0.50000\n         2           0.50725\n         3           0.51050\n         4           0.51700\n         5           0.51700\n         6           0.52375\n         7           0.53525\n         8           0.54375\n         9           0.54625\n        10           0.54875\n        11           0.54875\n        12           0.56150\n        13           0.56325\n        14           0.56700\n        15           0.57300\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv = KFold(n_splits=5) # Numero deseado de \"folds\" que haremos\n",
    "accuracies = list()\n",
    "depth_range = range(1, 16)\n",
    " \n",
    "# Testearemos la profundidad de 1 a cantidad de atributos +1\n",
    "for depth in depth_range:\n",
    "    fold_accuracy = []\n",
    "    tree_model = tree.DecisionTreeClassifier(criterion='entropy',\n",
    "                                             min_samples_split=20,\n",
    "                                             min_samples_leaf=5,\n",
    "                                             max_depth = depth,\n",
    "                                             class_weight={1:3.5})\n",
    "    for train_fold, valid_fold in cv.split(XT):\n",
    "        f_train = XT.loc[train_fold] \n",
    "        f_valid = XT.loc[valid_fold] \n",
    " \n",
    "        model = tree_model.fit(X = f_train.drop(['y'], axis=1),y = f_train['y'])\n",
    "        valid_acc = model.score(X = f_train.drop(['y'], axis= 1), y = f_train['y']) # calculamos la precision con el segmento de validacion\n",
    "        fold_accuracy.append(valid_acc)\n",
    " \n",
    "    avg = sum(fold_accuracy)/len(fold_accuracy)\n",
    "    accuracies.append(avg)\n",
    "    \n",
    "# Mostramos los resultados obtenidos\n",
    "df = pd.DataFrame({\"Max Depth\": depth_range, \"Average Accuracy\": accuracies})\n",
    "df = df[[\"Max Depth\", \"Average Accuracy\"]]\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "55.9\n"
     ]
    }
   ],
   "source": [
    "# Crear arrays de entrenamiento y las etiquetas que indican si llegó a top o no \n",
    "y_train = XT['y']\n",
    "x_train = XT.drop(['y'], axis=1).values \n",
    " \n",
    "# Crear Arbol de decision con profundidad = 4\n",
    "decision_tree = tree.DecisionTreeClassifier(criterion='entropy',\n",
    "                                            min_samples_split=15,\n",
    "                                            min_samples_leaf=5,\n",
    "                                            max_depth = 15,\n",
    "                                            class_weight={1:3.5})\n",
    "decision_tree.fit(x_train, y_train)\n",
    " \n",
    "acc_decision_tree = round(decision_tree.score(x_train, y_train) * 100, 2)\n",
    "print(acc_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred  = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[103  40]\n [ 43 114]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "tp = cm[0,[0]]\n",
    "tn = cm[1,[1]]\n",
    "fn = cm[1,[0]]\n",
    "fp = cm[0,[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CART: Accuracy: [0.72333333] Precision: [0.72027972] Recall: [0.70547945] F1: [0.71280277]\n"
     ]
    }
   ],
   "source": [
    "accu = (tp+tn)/(tp+tn+fn+fp)\n",
    "pre = tp/(tp+fp)\n",
    "rec = tp/(tp+fn)\n",
    "F1 = 2*pre*rec/(pre+rec)\n",
    "\n",
    "print('CART:', 'Accuracy:',accu, 'Precision:',pre, 'Recall:',rec, 'F1:',F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "multiple_linear_regression_new_version.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}